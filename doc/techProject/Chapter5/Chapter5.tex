% !TEX root = ../TechProject.tex

\graphicspath{{Chapter5/}}



\chapter{Application}

Inspired by the training data from a fader estimation investigation, \textit{MixesDB} is a website of archived DJ sets \citep{kim_automatic_2017}. With over 260,000 mixes on the site, using this as a dataset to train the model proved to be an excellent choice \citep{mixesdb_main_2023}. As mentioned in Chapter 2, Daniel Chow built a system that takes in a single song and outputs similar songs based on the \textit{MixesDB} dataset \citep{chow_music_2020}. His code will provide the foundation, which is built upon by the inclusion of multiple inputs and an extra layer of filtering.

\section{Data set}
As Chow details, data was scraped from the website \textit{MixesDB} done using Selenium \citep{chow_music_2020}. The tracks in a given DJ Set which had a corresponding Spotify link were stored with a given user ID for the DJ.  In cases where a single DJ set included multiple DJs, the set was considered as belonging to all the DJs involved, and the corresponding songs were linked to each DJ's user ID.  With the article being dated back in 2020, the data set only has DJ sets up to that year. The dataset has approximately 9900 DJ sets and 99100 songs. Figure 5.1 shows a DJ set from the dataset.
\\
\\
\\
\begin{figure}[H]
	\includegraphics[scale=0.45]{images/dataset}
	\centering
	\caption{Table showing a DJ Set in the dataset} 
\end{figure}


\section{Initial Suggestions}
As in Daniel Chows method, the initial suggestions part of the model is made using alternating least squares, a matrix factorisation algorithm that was made popular by the Netflix Prize award \citep{zhou_large-scale_2008}. As explained in Chapter 2, it provides a computational way of handling a dataset, and it splits the DJ song matrix to its latent factors, revealing trends in between songs and DJs.

A model is made from the dataset, then a list of songs gets inputted. A for loop is ran that will find similar items with the alternating least squares algorithm for each song. the number of recommended song suggestions for each song was set to 200, to assure a large amount of similar songs are used in the next part of the model.
\begin{figure}[H]{\noindent\ignorespaces}
	\includegraphics[scale=0.1]{images/application_app_flow}
	\centering
	\caption{A flow diagram of the application} 
\end{figure}

\section{Final Suggestions}
As of yet the code used is similar to Daniel Chow's, aside from iterating through many song inputs, instead of one \citep{chow_music_2020}. To add an extra layer of filtering, the Spotify API is used to further explore which songs are the most similar.

Using both the input songs, and initial suggestions, the Spotify API provides audio features for each song. The features used are shown below \citep{spotify_web_2023}:

\begin{enumerate}
	\item \textbf{acousticness} - A measure on how acoustic the song sounds (1 being definitely acoustic).
	\item \textbf{danceability} - Measurement on how suitable a track is for dancing based on tempo, rhythmic features and overall regularity. 1.0 is most danceable. 
	\item \textbf{energy} - A measurement of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. A heavy metal track would score high, but a Bach prelude would score low. Attributes include dynamic range, perceived loudness, timbre, onset rate, and general entropy will dictate this value. 1.0 is highly energetic.
	\item \textbf{instrumentalness} - Predicts whether a track contains no spoken vocals. Songs scoring 1 likely have no vocals. Values above 0.5 represent instrumental tracks.
	\item \textbf{key} - The key the track is in uses following notation 0 = C, 1 = C$\sharp$/D$\flat$, 2 = D. If key cannot be detected then value is set to -1.
	\item \textbf{loudness} - Loudness of a given track in dB
	\item \textbf{tempo} - The beats per minute of a given track.
	\item \textbf{time\_signature} - Time signature with the following notation, 3 = 3/4, 4= 4/4, 5 = 5/4.
	\item \textbf{speechiness} - Detects if a song has spoken word, audio books would score 1 and values ranging from 0.3-0.6 would be combination of music and speech.
	\item \textbf{valence} - A measurement of how positive a song is. With scores of 1 being extremely positive.
	
\end{enumerate}

These features provided great data to form vectors out of for each song, as they highlight attributes of a song which makes them unique. Attributes like tempo is especially helpful for improving the recommendations for DJ Sets, due to being the controlled variable when it comes to transition from one song to another.

The input contains many songs, so for calculating euclidean distance, a mean vector is created from all the input song vectors. The vectors are then scaled. This step is crucial because some attributes work with different ranges, examples being loudness uses dB range and acousticness is from 0-1.

Once these are found, euclidean distance between each initially suggested songs vector and the input average vector is calculated. As discussed in chapter 2, euclidean distance is a way of measuring the distance between two vectors. An equation is show below, allowing $x_{i}$ and $y_{i}$ to be two song vectors.

\begin{equation}
	d(x,y) = \sqrt{\sum _{i=1} ^{n}(x_{i} - y_{i})^{2}}
\end{equation}

For finding the vectors with the smallest distance between the mean input, this is a clear representation that a given song has similar Spotify features attributes, therefore would be a worthy suggestions based on the recommended songs.

\section{Example Findings}
To demonstrate the application in a non methodical way. A variety of DJ Set tracklists corresponding to different genres were used as inputs for the application.  Three different DJ sets were used:

\begin{itemize}
	\item \textbf{Rory Bowens, PLO Man, C3D-E, Brian Not Brian - The Slip, NTS Radio: } 
	\begin{itemize}
		\item \textbf{Genre:} New wave \& House
		\item \textbf{Tracks available:} 3/21
	\end{itemize}
	\item \textbf{Moxie, Shanti Celeste, Chris Farrell - NTS Radio: } 
	\begin{itemize}
		\item \textbf{Genre:} Tech-House
		\item \textbf{Tracks available:} 10/28
	\end{itemize}
	\item \textbf{Chimpo b2b L U C Y @ Keep Hush Live: Sherelle Presents:}
	\begin{itemize}
		\item \textbf{Genre:} Jungle \& Breaks
		\item \textbf{Tracks available:} 8/21
	\end{itemize}
	
\end{itemize}


When going through the recommended songs, the BPMs of the output songs were observed to see if they were around the same range as the input songs. The songs were listened to see if stylistically they were similar to the input songs, and the source of the recommended songs were also observed.

The Slip set performed okay. Expectations were low due to the small amount of tracks available. Two of them had a House style to them and one was Indie. The output songs were all House songs and none matched stylistically to the one indie song. However, all the BPM's were in a similar range around 110-120 BPM. The Moxie set performed very well. The input songs were all Tech-House songs and the output songs were that as well with a couple of more disco inspired tunes. BPM's were all very similar as well. The Keep Hush set also gave good results. The BPM ranges were similar to the input songs and stylistically matched the input songs well. 

All the suggested tunes did not come from an eclectic mix of DJ Sets or DJs, in each batch of suggestions a lot of songs were either from the same mix or the same DJ. This is most likely due to the sparsity of the dataset, which is value of 99.98\% is not ideal for a training set. 

The intent of displaying this is more to show the application in action rather than dissecting the quality of its performance which is analysed in the Experiment chapter. A table of the input and recommended songs for the Moxie DJ set is shown below.
\\
\\
\\
\begin{center}
	\begin{tabular}{ |c|} 
		\hline
		\textbf{Moxie, Shanti Celeste, Chris Farrell - NTS Radio}\\ 
		\hline \textbf{Input Songs}\\ 
		\hline Escape Earth \textit{Gravity Well} \\ 
		\hline Priori \textit{6thematic }\\
		\hline Carter Bros. \textit{Run - Monty's Bonus Beats}\\
		\hline Tyler Dancer \textit{Karm√°n Line}\\ 
		\hline Anunaku \textit{Forgotton Tales}\\
		\hline Piezo \textit{Tinned}\\
		\hline KMA Production \textit{Cape Fear}\\
		\hline Parris \textit{Dusty Glass Bubbles}\\
		\hline Tornado Wallace \textit{Open Door - Born Inna Tent Mix}\\
		\hline Luke Slater \textit{I Want You Too}\\
		\hline \textbf{Recommended Songs}\\ 
		\hline Black Booby \textit{Fill My Cup}\\
		\hline Omar S, John FM \textit{Heard'chew Single}\\
		\hline Hammer \textit{Manaka}\\
		\hline Awanto 3 \textit{Pregnant}\\
		\hline Steve Murphy \textit{Next Saturday - Club Mix}\\
		\hline Chasindub \textit{Still Here}\\
		\hline Ian Pooley \textit{Swing Mode}\\
		\hline Hashin \textit{Al-Naafyish (The Soul) - The "It's" About "Time" Remix}\\
		\hline Synkro \textit{Look at Yourself}\\
		\hline Kapote \textit{Uhh Baby - Brame \& Hamo Remix}\\
		\hline
	\end{tabular}
\end{center}


\section{Summary}
An overview of the proposed application was given. The first part described the alternating least squares method that is borrowed from Daniel Chow's model. Then the audio features found through the Spotify API was explained, and how it was used to form vectors. These vectors were then used to filter through the recommendations further. A non methodical demonstration was conducted showing pretty good recommendations.


